# 2. 프롬프트 엔지니어링 원 포인트 레슨

## ch4. 프롬프트 엔지니어링이란

AI와 긴밀하게 소통하면서 원하는 결과를 얻어내는 프롬프트를 만들어 나가는 과정.

대표적인 다섯지 방법이 있는데,

**첫째, 제로샷 프롬프팅**

이것은 LLM에게 아무런 데이터나 예시를 주지 않고 바로 특정 작업을 수행하도록 지시하는 것이다.

정확도가 높지 않고 모호하거나 부정확한 대답 내놓을 가능성이 크다.

**둘째, 원샷 러닝**

LLM에게 명령을 내릴 때 실행 방법에 대한 예시 한 개를 동시에 제공하는 것이다.

마치 새로운 게임을 시작할 때 규칙 서명을 듣고 게임을 실행하는 것과 유사하다.

**셋째, 퓨삿 러닝**

마치 조리법을 배울 때 여러 가지 예시를 참고하는 것 처럼, LLM에게 특정 명령을 내릴 때 2~3개부터 수십 개 정도의 예시를 함께 제공한다.

데이터가 부족하거나 특정 작업에 대한 사례가 많지 않을 때 특히 더 유용하다.

**넷째, CoT**

‘생각 사슬’ 이라고 불린다. 마치 복잡한 수학 문제를 풀기 위해 문제를 쪼개어 단계적으로 푸는 것과 유사하다.

이 방식의 핵심은 AI가 단순히 결과를 도출하는게 아니라 문제 해결 과정에 필요한 논리적 사고를 모방하도록 하는 것이다.

따라서 특히 복잡한 해결과 추론을 요구하는 작업에 유용하고, AI의 이해력과 추론 능력을 크게 향상시킬 수 있다.

**다섯째, 제로샷 CoT**

CoT와 비슷한 방식이지만 문제 해결 과정에서 따라야 할 생각의 단계나 논리적 순서 등의 가이드를 주지 않는다.

---

프롬프트 엔지니어링은 **한 번 그럴 듯 한 결과를 내고 끝내는 것이 아니라 원하는 결과를 정확히 의도한 대로, 항상 일관되게 만드는 것이 목표**이다.

아래는 기본적인 프롬프트 구성이다. 

**1. 답변을 위해 필요한 적절한 컨텍스트 제공**
    1. AI는 주어진 정보를 참고해서 환각(할루시네이션)이 없는 더 정확한 응답을 생성할 수 있다.
**2. 원하는 결과 추출을 위한 프롬프트 작성**
**3. 결과물의 형식을 지정**

위 구성에서 중요한 단계는 사용자가 답변을 위해 사전에 어떤 문맥, **즉 어떤 컨텍스트를 제공하느냐** 이다. 이 컨텍스트는 LLM이 질문을 이해하고 그에 맞는 답변을 생성하는데 필수적이다.

아주 재밌는 예시가 책에 소개되어있는데 ChatGPT에게 새종대왕의 맥북프로 던짐 사건에 대해 알려달라고 했더니 마치 실제 있었던 사실인냥 이야기를 지어냈다는 것이다.

LLM은 어떻게든 말을 조합해 만들어내는 특성이 있기 때문에 이러한 일이 발생한다.

Bing Chat에게 저 터무니없는 질문을 했을 때는 그런일이 발생한 적 없다는 사실을 얘기한다. 그러나 ChatGPT에게 같은 질문을 했을 때 저러한 답변이 나오는 데 그 이유는 **인컨텍스트 러닝**의 유무 때문이다. 

*인컨텍스트 러닝이란?

양질의 답변을 위해 적절한 컨텍스트를 제공하고 활용하는 것. 

Bing Chat은 진짜 저러한 사건이 있었는지 웹에서 검색한 결과를 LLM에게 전달한다. 그러나 ChatGPT는 프롬프트로 요청을 하면 바로 답변을 생성하기 때문에 제대로 된 정보를 제공할 수 없다.

## ch.5 컨텍스트를 가져오는 기술 - 벡터 서치

단어가 낯설어서 단어 위주로 정리!

- 임베딩: LLM에서 **임베딩**이란 단어나 문장 같은 언어의 조각들을 숫자로 바꾸는 과정을 말한다.
- 벡터화: 각 단어들을 숫자의 집합, 즉 실수 형태의 집합으로 바꾸는 과정
- 임베딩 벡터: 이렇게 변환된 숫자의 집합

우리가 LLM을 사용할 때는 일반 텍스트로 프롬프트를 입력하지만 실제로 LLM 모델이 받아들이는 것은 이렇게 벡터화된 데이터 이다.

- 벡터 서치(시멘틱 서치): 임베딩 공간에서 기준이 되는 단어와 가까운 단어를 찾는 것

단어 뿐 만 아니라 문장도 임베딩이 가능하다.

- 단점
    - 속도 문제. 대규모 계산은 기본적으로 처리 속도 문제에 한계가 있다.
    - 성능 문제. 일부 정보 손실이나 정확도 감소의 문제가 있을 수 있다.
